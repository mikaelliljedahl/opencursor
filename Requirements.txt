# OpenCursor - Intelligent Developer Assistant

## Purpose
OpenCursor is a lightweight mix of console and WPF-based tools designed to assist developers in software development with the help of Large Language Models (LLMs). It facilitates:
- **File Navigation**: Users explore project files interactively and mark those that needs attention
- **Multi-Role LLM Interaction**: Different LLM sessions assist in requirements analysis, development, code verification, and integration.
- **MCP-Based Code Execution**: LLM-generated suggestions are applied to the codebase using structured commands.

---

## Architecture Overview
**Components:**
1. **Console Application** (Helper Interface)
2. **WPF-Based Browser UI** (User interaction and LLM Interaction)
3. **Multi-Session LLM Handling**
4. **Local HTTP Communication & MCP Protocol**
 
**LLM Roles:**
- **Requirements Analyst**: Extracts and refines software needs.
- **Developer Role**: Writes and suggests code modifications.
- **Code Verifier**: Ensures correctness and best practices.
- **Code Application & MCP Integration**: Applies confirmed changes.

---

## Key Requirements

### **1. Console Application**
- **Technology Stack**:  
  - C# (.NET 8 or later)
  - Uses top-level statements in `Program.cs`
  - Organized for separation of concerns:
    - `DirectoryBrowser.cs` (File System Navigation)
    - `KeyboardNavigator.cs` (Keyboard Interaction)
    - `LLMClient.cs` and `LLMServer.cs` (LLM Prompt Handling & Code Application)

- **User Experience**:
  - Inspired by classic tools like Norton Commander to select active directory in the console app.
  - **Keyboard controls**:
    - Arrow keys → Move cursor.
    - Tab → Switch panels.
    - `+` → Select file/directory.
    - `-` → Deselect file/directory.
    - Enter → Open folders.
    - Function keys (`F1`-`F10`) → Special commands.

---

### **2. LLM Communication & MCP Protocol**
- **Multi-Session LLM Handling**:
  - Separate interactions for requirements analysis, development, and validation.
  - Server implemented according to: https://github.com/modelcontextprotocol/csharp-sdk

- **Prompt Construction**:
  - Collects selected files and directories.
  - Instructions for allowed actions:
    - File creation, updates, deletion.
    - Searching for relevant code snippets/classes.
  - Includes:
    - Marked file paths.
    - Relevant file contents.
    - Contextual directory insights.

- **Model Context Protocol Based Code Execution**:
  - Commands that should be available for the LLM will be called using the MCP protocol:
    
---

### **3. Communication Flow**
- **Local HTTP interactions**:
  - Console app and the WPF App that hosts the interaction with the LLM will communicate using Websocket connections
    ```
  - WPF App captures responses and send results to instances of the console application that e.g. can apply code changes:
    ```
  - The console app **validates and applies** confirmed changes.
  - The WPF app could also call an LLM using the Google Gemini API.


---

### **4. WPF-Based UI**
- Displays **LLM responses** and refinement options using a builtin UI.
- Supports **interactive validation** before applying modifications.
- Tracks **history** of applied changes.
- Spawn the console app.

---

## Core Components

1.  **Console Application (`OpenCursor.Client`):**
    *   Displays the file/directory browser UI.
    *   Handles keyboard navigation (up, down, enter, space for marking).
    *   Manages the list of marked files/directories.
    *   Receives parsed commands (file operations, command execution) from the WPF application via WebSocket.
    *   Executes the received commands (create/update/delete files, run shell commands) using the McpProcessor.
    *   Hosts a WebSocket server (`ws://localhost:12346/`) to listen for commands from the WPF app.

2.  **WPF Application (`OpenCursor.BrowserHost`):**
    *   Provides the main user interface for interacting with the Large Language Model (LLM).
    *   Connects directly to the Google Gemini REST API.
    *   Requires configuration for the Google API Key and Model Endpoint (must handle API key securely).
    *   Displays the conversation history (user prompts and LLM responses).
    *   Allows the user to type and send messages to the LLM via the API.
    *   Loads a system prompt (`systemprompt.md`) to provide context/instructions to the LLM.
    *   Sends the raw text response received from the Google Gemini API to the Console application via a WebSocket connection (`ws://localhost:12346/`).
    *   Acts as a WebSocket client connecting to the Console app's server.

---

## Technology Stack

*   .NET (latest stable version, e.g., .NET 8)
*   C#
*   WPF for the GUI application (`OpenCursor.BrowserHost`)
*   Console Application (`OpenCursor.Client`)
*   System.Net.Http for Google Gemini API calls.
*   System.Net.WebSockets for communication between WPF and Console apps.
*   System.Text.Json for API request/response serialization.
*   (Optional) Configuration system for API keys/endpoints (e.g., appsettings.json, User Secrets).

## Interaction Flow

1.  User navigates filesystem in the Console App.
2.  User interacts with the LLM via the WPF App.
3.  WPF App sends user message + history + system prompt to Google Gemini API.
4.  Google Gemini API responds with generated text.
5.  WPF App displays the LLM response.
6.  WPF App sends the raw LLM response string to the Console App via WebSocket.
7.  Console App's WebSocket server receives the string.
8.  Console App parses the string for XML-like commands (`<create_file>`, `<execute_command>`, etc.) using `LlmResponseParser`.
9.  Console App executes the parsed commands using `McpProcessor` relative to its current directory.

---

## Supported Client Commands (JSON Function Calls from LLM):

The Console Client (`OpenCursor.Client`) must parse and execute the following commands received as JSON objects within the LLM's response via the WebSocket connection:

1.  **`codebase_search`**: Performs semantic search.
    *   `parameters`: `query` (string), `target_directories` (string[]?)
2.  **`read_file`**: Reads content from a file.
    *   `parameters`: `relative_workspace_path` (string), `should_read_entire_file` (bool), `start_line_one_indexed` (int?), `end_line_one_indexed_inclusive` (int?)
3.  **`run_terminal_cmd`**: Executes a shell command.
    *   `parameters`: `command` (string), `is_background` (bool), `require_user_approval` (bool)
4.  **`list_dir`**: Lists contents of a directory.
    *   `parameters`: `relative_workspace_path` (string)
5.  **`grep_search`**: Performs text/regex search (like ripgrep).
    *   `parameters`: `query` (string), `case_sensitive` (bool?), `include_pattern` (string?), `exclude_pattern` (string?)
6.  **`file_search`**: Fuzzy finds files by path.
    *   `parameters`: `query` (string)
7.  **`delete_file`**: Deletes a specified file.
    *   `parameters`: `target_file` (string) (Mapped to `RelativePath` in C# class)

(Note: Commands like `edit_file`, `reapply`, `parallel_apply` are instructions for the LLM agent itself and are not processed by the client.)

---

## Future Enhancements
- **Plugin System**: Allows extensibility.
- **LLM Multi-Agent Collaboration**: Dynamic role-switching for different needs.
- **Code Refactoring Assistance**: Suggests improvements.
- **Automated Debugging & Error Detection**.
- **Inline Comments for Code Rationalization**.
